{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "print(__doc__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import _zconfint_generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Loading the Digits dataset\n",
    "# digits = datasets.load_digits()\n",
    "\n",
    "# # To apply an classifier on this data, we need to flatten the image, to\n",
    "# # turn the data in a (samples, feature) matrix:\n",
    "# n_samples = len(digits.images)\n",
    "# X = digits.images.reshape((n_samples, -1))\n",
    "# y = digits.target\n",
    "dataset=np.loadtxt('transfusion.txt', delimiter=',', dtype=str, )\n",
    "dataset=[[float(n) for n in e] for e in dataset]\n",
    "X=[]\n",
    "y=[]\n",
    "for row in dataset:\n",
    "    X.append(row[:4])\n",
    "    y.append(int(row[4]))\n",
    "X=np.array(X)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "scores = ['precision', 'recall', 'f1', 'accuracy', 'roc_auc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.231 (+/-0.408) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.301 (+/-0.800) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.510 (+/-0.127) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.157 (+/-0.270) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.417 (+/-0.199) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.428 (+/-0.182) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.359 (+/-0.244) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.460 (+/-0.130) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.90      0.86       285\n",
      "          1       0.54      0.37      0.44        89\n",
      "\n",
      "avg / total       0.75      0.78      0.76       374\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.056 (+/-0.099) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.022 (+/-0.054) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.270 (+/-0.086) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.056 (+/-0.099) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.248 (+/-0.184) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.202 (+/-0.164) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.247 (+/-0.180) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.248 (+/-0.095) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.90      0.86       285\n",
      "          1       0.54      0.37      0.44        89\n",
      "\n",
      "avg / total       0.75      0.78      0.76       374\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.086 (+/-0.148) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.041 (+/-0.101) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.349 (+/-0.073) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.080 (+/-0.140) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.309 (+/-0.202) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.262 (+/-0.145) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.292 (+/-0.206) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.320 (+/-0.108) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.90      0.86       285\n",
      "          1       0.54      0.37      0.44        89\n",
      "\n",
      "avg / total       0.75      0.78      0.76       374\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.746 (+/-0.043) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.743 (+/-0.063) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.762 (+/-0.041) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.722 (+/-0.045) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.743 (+/-0.051) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.741 (+/-0.059) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.717 (+/-0.082) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.751 (+/-0.041) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.90      0.86       285\n",
      "          1       0.54      0.37      0.44        89\n",
      "\n",
      "avg / total       0.75      0.78      0.76       374\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.614 (+/-0.089) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.616 (+/-0.163) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.623 (+/-0.064) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.593 (+/-0.081) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.622 (+/-0.073) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.577 (+/-0.097) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.563 (+/-0.111) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.594 (+/-0.122) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.90      0.86       285\n",
      "          1       0.54      0.37      0.44        89\n",
      "\n",
      "avg / total       0.75      0.78      0.76       374\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n",
    "                       scoring= score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.566 (+/-0.777) for {'C': 1, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.549 (+/-0.800) for {'C': 1, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.549 (+/-0.800) for {'C': 10, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.549 (+/-0.800) for {'C': 10, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.549 (+/-0.800) for {'C': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.549 (+/-0.800) for {'C': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.549 (+/-0.800) for {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.549 (+/-0.800) for {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.98      0.87       285\n",
      "          1       0.69      0.12      0.21        89\n",
      "\n",
      "avg / total       0.76      0.78      0.71       374\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.067 (+/-0.109) for {'C': 1, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.067 (+/-0.109) for {'C': 1, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.067 (+/-0.109) for {'C': 10, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.067 (+/-0.109) for {'C': 10, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.067 (+/-0.109) for {'C': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.067 (+/-0.109) for {'C': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.067 (+/-0.109) for {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.067 (+/-0.109) for {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.98      0.87       285\n",
      "          1       0.69      0.12      0.21        89\n",
      "\n",
      "avg / total       0.76      0.78      0.71       374\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.118 (+/-0.186) for {'C': 1, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.118 (+/-0.186) for {'C': 1, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.118 (+/-0.186) for {'C': 10, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.118 (+/-0.186) for {'C': 10, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.118 (+/-0.186) for {'C': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.118 (+/-0.186) for {'C': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.118 (+/-0.186) for {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.118 (+/-0.186) for {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.98      0.87       285\n",
      "          1       0.69      0.12      0.21        89\n",
      "\n",
      "avg / total       0.76      0.78      0.71       374\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.762 (+/-0.053) for {'C': 1, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.762 (+/-0.053) for {'C': 1, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.762 (+/-0.053) for {'C': 10, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.762 (+/-0.053) for {'C': 10, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.762 (+/-0.053) for {'C': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.762 (+/-0.053) for {'C': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.762 (+/-0.053) for {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.762 (+/-0.053) for {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.98      0.87       285\n",
      "          1       0.69      0.12      0.21        89\n",
      "\n",
      "avg / total       0.76      0.78      0.71       374\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.713 (+/-0.049) for {'C': 1, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.713 (+/-0.048) for {'C': 1, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.713 (+/-0.053) for {'C': 10, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.712 (+/-0.054) for {'C': 10, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.714 (+/-0.057) for {'C': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.712 (+/-0.054) for {'C': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.712 (+/-0.053) for {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.713 (+/-0.054) for {'C': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.98      0.87       285\n",
      "          1       0.69      0.12      0.21        89\n",
      "\n",
      "avg / total       0.76      0.78      0.71       374\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset in two equal parts\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.5, random_state=0)\n",
    "# scores = ['precision', 'recall', 'f1']\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'penalty': ['l1'],'solver': ['liblinear'], 'tol': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(LogisticRegression(C=1), tuned_parameters, cv=5,\n",
    "                       scoring=score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'algorithm': 'ball_tree', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.282 (+/-0.182) for {'algorithm': 'ball_tree', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.409 (+/-0.272) for {'algorithm': 'ball_tree', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "0.415 (+/-0.093) for {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.307 (+/-0.432) for {'algorithm': 'ball_tree', 'n_neighbors': 4, 'weights': 'uniform'}\n",
      "0.389 (+/-0.182) for {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.196 (+/-0.391) for {'algorithm': 'ball_tree', 'n_neighbors': 6, 'weights': 'uniform'}\n",
      "0.403 (+/-0.331) for {'algorithm': 'ball_tree', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.494 (+/-0.851) for {'algorithm': 'ball_tree', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "0.443 (+/-0.669) for {'algorithm': 'ball_tree', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "0.284 (+/-0.178) for {'algorithm': 'kd_tree', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.409 (+/-0.272) for {'algorithm': 'kd_tree', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "0.421 (+/-0.086) for {'algorithm': 'kd_tree', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.307 (+/-0.432) for {'algorithm': 'kd_tree', 'n_neighbors': 4, 'weights': 'uniform'}\n",
      "0.389 (+/-0.182) for {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.196 (+/-0.391) for {'algorithm': 'kd_tree', 'n_neighbors': 6, 'weights': 'uniform'}\n",
      "0.403 (+/-0.331) for {'algorithm': 'kd_tree', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.494 (+/-0.851) for {'algorithm': 'kd_tree', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "0.443 (+/-0.669) for {'algorithm': 'kd_tree', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "0.277 (+/-0.161) for {'algorithm': 'brute', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.403 (+/-0.272) for {'algorithm': 'brute', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "0.415 (+/-0.093) for {'algorithm': 'brute', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.307 (+/-0.432) for {'algorithm': 'brute', 'n_neighbors': 4, 'weights': 'uniform'}\n",
      "0.396 (+/-0.171) for {'algorithm': 'brute', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.196 (+/-0.391) for {'algorithm': 'brute', 'n_neighbors': 6, 'weights': 'uniform'}\n",
      "0.403 (+/-0.331) for {'algorithm': 'brute', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.494 (+/-0.851) for {'algorithm': 'brute', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "0.463 (+/-0.680) for {'algorithm': 'brute', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.96      0.86       285\n",
      "          1       0.52      0.15      0.23        89\n",
      "\n",
      "avg / total       0.72      0.76      0.71       374\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'algorithm': 'ball_tree', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.247 (+/-0.180) for {'algorithm': 'ball_tree', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.101 (+/-0.084) for {'algorithm': 'ball_tree', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "0.247 (+/-0.150) for {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.079 (+/-0.115) for {'algorithm': 'ball_tree', 'n_neighbors': 4, 'weights': 'uniform'}\n",
      "0.192 (+/-0.159) for {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.033 (+/-0.054) for {'algorithm': 'ball_tree', 'n_neighbors': 6, 'weights': 'uniform'}\n",
      "0.101 (+/-0.082) for {'algorithm': 'ball_tree', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.045 (+/-0.045) for {'algorithm': 'ball_tree', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "0.090 (+/-0.113) for {'algorithm': 'ball_tree', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "0.247 (+/-0.180) for {'algorithm': 'kd_tree', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.101 (+/-0.084) for {'algorithm': 'kd_tree', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "0.247 (+/-0.150) for {'algorithm': 'kd_tree', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.079 (+/-0.115) for {'algorithm': 'kd_tree', 'n_neighbors': 4, 'weights': 'uniform'}\n",
      "0.192 (+/-0.159) for {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.033 (+/-0.054) for {'algorithm': 'kd_tree', 'n_neighbors': 6, 'weights': 'uniform'}\n",
      "0.101 (+/-0.082) for {'algorithm': 'kd_tree', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.045 (+/-0.045) for {'algorithm': 'kd_tree', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "0.090 (+/-0.113) for {'algorithm': 'kd_tree', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "0.247 (+/-0.180) for {'algorithm': 'brute', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.090 (+/-0.057) for {'algorithm': 'brute', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "0.247 (+/-0.150) for {'algorithm': 'brute', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.079 (+/-0.115) for {'algorithm': 'brute', 'n_neighbors': 4, 'weights': 'uniform'}\n",
      "0.191 (+/-0.136) for {'algorithm': 'brute', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.033 (+/-0.054) for {'algorithm': 'brute', 'n_neighbors': 6, 'weights': 'uniform'}\n",
      "0.101 (+/-0.082) for {'algorithm': 'brute', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.045 (+/-0.045) for {'algorithm': 'brute', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "0.101 (+/-0.129) for {'algorithm': 'brute', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.80      0.81       285\n",
      "          1       0.41      0.46      0.44        89\n",
      "\n",
      "avg / total       0.73      0.72      0.72       374\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'algorithm': 'kd_tree', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.259 (+/-0.165) for {'algorithm': 'ball_tree', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.158 (+/-0.115) for {'algorithm': 'ball_tree', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "0.301 (+/-0.112) for {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.122 (+/-0.167) for {'algorithm': 'ball_tree', 'n_neighbors': 4, 'weights': 'uniform'}\n",
      "0.245 (+/-0.152) for {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.055 (+/-0.091) for {'algorithm': 'ball_tree', 'n_neighbors': 6, 'weights': 'uniform'}\n",
      "0.155 (+/-0.123) for {'algorithm': 'ball_tree', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.078 (+/-0.081) for {'algorithm': 'ball_tree', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "0.138 (+/-0.166) for {'algorithm': 'ball_tree', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "0.260 (+/-0.164) for {'algorithm': 'kd_tree', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.158 (+/-0.115) for {'algorithm': 'kd_tree', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "0.304 (+/-0.116) for {'algorithm': 'kd_tree', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.122 (+/-0.167) for {'algorithm': 'kd_tree', 'n_neighbors': 4, 'weights': 'uniform'}\n",
      "0.245 (+/-0.152) for {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.055 (+/-0.091) for {'algorithm': 'kd_tree', 'n_neighbors': 6, 'weights': 'uniform'}\n",
      "0.155 (+/-0.123) for {'algorithm': 'kd_tree', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.078 (+/-0.081) for {'algorithm': 'kd_tree', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "0.138 (+/-0.166) for {'algorithm': 'kd_tree', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "0.258 (+/-0.163) for {'algorithm': 'brute', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.145 (+/-0.085) for {'algorithm': 'brute', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "0.301 (+/-0.112) for {'algorithm': 'brute', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.122 (+/-0.167) for {'algorithm': 'brute', 'n_neighbors': 4, 'weights': 'uniform'}\n",
      "0.246 (+/-0.122) for {'algorithm': 'brute', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.055 (+/-0.091) for {'algorithm': 'brute', 'n_neighbors': 6, 'weights': 'uniform'}\n",
      "0.155 (+/-0.123) for {'algorithm': 'brute', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.078 (+/-0.081) for {'algorithm': 'brute', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "0.154 (+/-0.193) for {'algorithm': 'brute', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.86      0.82       285\n",
      "          1       0.38      0.28      0.32        89\n",
      "\n",
      "avg / total       0.69      0.72      0.70       374\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'algorithm': 'ball_tree', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.668 (+/-0.095) for {'algorithm': 'ball_tree', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.749 (+/-0.041) for {'algorithm': 'ball_tree', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "0.735 (+/-0.044) for {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.743 (+/-0.040) for {'algorithm': 'ball_tree', 'n_neighbors': 4, 'weights': 'uniform'}\n",
      "0.730 (+/-0.067) for {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.738 (+/-0.048) for {'algorithm': 'ball_tree', 'n_neighbors': 6, 'weights': 'uniform'}\n",
      "0.738 (+/-0.089) for {'algorithm': 'ball_tree', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.746 (+/-0.064) for {'algorithm': 'ball_tree', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "0.746 (+/-0.062) for {'algorithm': 'ball_tree', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "0.671 (+/-0.088) for {'algorithm': 'kd_tree', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.749 (+/-0.041) for {'algorithm': 'kd_tree', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "0.738 (+/-0.038) for {'algorithm': 'kd_tree', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.743 (+/-0.040) for {'algorithm': 'kd_tree', 'n_neighbors': 4, 'weights': 'uniform'}\n",
      "0.730 (+/-0.067) for {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.738 (+/-0.048) for {'algorithm': 'kd_tree', 'n_neighbors': 6, 'weights': 'uniform'}\n",
      "0.738 (+/-0.089) for {'algorithm': 'kd_tree', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.746 (+/-0.064) for {'algorithm': 'kd_tree', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "0.746 (+/-0.062) for {'algorithm': 'kd_tree', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "0.668 (+/-0.079) for {'algorithm': 'brute', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.749 (+/-0.041) for {'algorithm': 'brute', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "0.735 (+/-0.044) for {'algorithm': 'brute', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.743 (+/-0.040) for {'algorithm': 'brute', 'n_neighbors': 4, 'weights': 'uniform'}\n",
      "0.730 (+/-0.067) for {'algorithm': 'brute', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.738 (+/-0.048) for {'algorithm': 'brute', 'n_neighbors': 6, 'weights': 'uniform'}\n",
      "0.738 (+/-0.089) for {'algorithm': 'brute', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.746 (+/-0.064) for {'algorithm': 'brute', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "0.749 (+/-0.065) for {'algorithm': 'brute', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.95      0.86       285\n",
      "          1       0.46      0.13      0.21        89\n",
      "\n",
      "avg / total       0.70      0.76      0.70       374\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'algorithm': 'brute', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.523 (+/-0.098) for {'algorithm': 'ball_tree', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.593 (+/-0.093) for {'algorithm': 'ball_tree', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "0.598 (+/-0.049) for {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.588 (+/-0.049) for {'algorithm': 'ball_tree', 'n_neighbors': 4, 'weights': 'uniform'}\n",
      "0.585 (+/-0.059) for {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.593 (+/-0.057) for {'algorithm': 'ball_tree', 'n_neighbors': 6, 'weights': 'uniform'}\n",
      "0.585 (+/-0.078) for {'algorithm': 'ball_tree', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.584 (+/-0.080) for {'algorithm': 'ball_tree', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "0.588 (+/-0.073) for {'algorithm': 'ball_tree', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "0.525 (+/-0.094) for {'algorithm': 'kd_tree', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.593 (+/-0.093) for {'algorithm': 'kd_tree', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "0.599 (+/-0.053) for {'algorithm': 'kd_tree', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.589 (+/-0.053) for {'algorithm': 'kd_tree', 'n_neighbors': 4, 'weights': 'uniform'}\n",
      "0.585 (+/-0.059) for {'algorithm': 'kd_tree', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.594 (+/-0.059) for {'algorithm': 'kd_tree', 'n_neighbors': 6, 'weights': 'uniform'}\n",
      "0.586 (+/-0.079) for {'algorithm': 'kd_tree', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.584 (+/-0.080) for {'algorithm': 'kd_tree', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "0.588 (+/-0.073) for {'algorithm': 'kd_tree', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "0.523 (+/-0.091) for {'algorithm': 'brute', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.585 (+/-0.079) for {'algorithm': 'brute', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "0.600 (+/-0.082) for {'algorithm': 'brute', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.592 (+/-0.048) for {'algorithm': 'brute', 'n_neighbors': 4, 'weights': 'uniform'}\n",
      "0.586 (+/-0.067) for {'algorithm': 'brute', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "0.589 (+/-0.063) for {'algorithm': 'brute', 'n_neighbors': 6, 'weights': 'uniform'}\n",
      "0.582 (+/-0.076) for {'algorithm': 'brute', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "0.588 (+/-0.080) for {'algorithm': 'brute', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "0.587 (+/-0.089) for {'algorithm': 'brute', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.86      0.82       285\n",
      "          1       0.38      0.27      0.31        89\n",
      "\n",
      "avg / total       0.69      0.72      0.70       374\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'n_neighbors': [1, 2, 3, 4, 5, 6,7,8,9],'weights': ['uniform'], 'algorithm': ['ball_tree']},\n",
    "                    {'n_neighbors': [1, 2, 3, 4, 5, 6,7,8,9],'weights': ['uniform'], 'algorithm': ['kd_tree']},\n",
    "                    {'n_neighbors': [1, 2, 3, 4, 5, 6,7,8,9],'weights': ['uniform'], 'algorithm': ['brute']}]\n",
    "\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(KNeighborsClassifier(n_neighbors=1), tuned_parameters, cv=5,\n",
    "                       scoring=score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 3}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.166 (+/-0.421) for {'criterion': 'gini', 'max_depth': 2}\n",
      "0.588 (+/-0.447) for {'criterion': 'gini', 'max_depth': 3}\n",
      "0.432 (+/-0.216) for {'criterion': 'gini', 'max_depth': 4}\n",
      "0.456 (+/-0.400) for {'criterion': 'gini', 'max_depth': 5}\n",
      "0.448 (+/-0.418) for {'criterion': 'gini', 'max_depth': 6}\n",
      "0.364 (+/-0.141) for {'criterion': 'gini', 'max_depth': 7}\n",
      "0.166 (+/-0.421) for {'criterion': 'entropy', 'max_depth': 2}\n",
      "0.588 (+/-0.447) for {'criterion': 'entropy', 'max_depth': 3}\n",
      "0.437 (+/-0.262) for {'criterion': 'entropy', 'max_depth': 4}\n",
      "0.433 (+/-0.310) for {'criterion': 'entropy', 'max_depth': 5}\n",
      "0.498 (+/-0.312) for {'criterion': 'entropy', 'max_depth': 6}\n",
      "0.410 (+/-0.099) for {'criterion': 'entropy', 'max_depth': 7}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.89      0.86       285\n",
      "          1       0.55      0.44      0.49        89\n",
      "\n",
      "avg / total       0.77      0.78      0.77       374\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 6}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.023 (+/-0.056) for {'criterion': 'gini', 'max_depth': 2}\n",
      "0.201 (+/-0.276) for {'criterion': 'gini', 'max_depth': 3}\n",
      "0.201 (+/-0.285) for {'criterion': 'gini', 'max_depth': 4}\n",
      "0.282 (+/-0.280) for {'criterion': 'gini', 'max_depth': 5}\n",
      "0.236 (+/-0.167) for {'criterion': 'gini', 'max_depth': 6}\n",
      "0.259 (+/-0.117) for {'criterion': 'gini', 'max_depth': 7}\n",
      "0.023 (+/-0.056) for {'criterion': 'entropy', 'max_depth': 2}\n",
      "0.201 (+/-0.276) for {'criterion': 'entropy', 'max_depth': 3}\n",
      "0.257 (+/-0.257) for {'criterion': 'entropy', 'max_depth': 4}\n",
      "0.282 (+/-0.280) for {'criterion': 'entropy', 'max_depth': 5}\n",
      "0.327 (+/-0.172) for {'criterion': 'entropy', 'max_depth': 6}\n",
      "0.315 (+/-0.183) for {'criterion': 'entropy', 'max_depth': 7}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.90      0.85       285\n",
      "          1       0.52      0.35      0.42        89\n",
      "\n",
      "avg / total       0.74      0.77      0.75       374\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 6}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.040 (+/-0.098) for {'criterion': 'gini', 'max_depth': 2}\n",
      "0.261 (+/-0.283) for {'criterion': 'gini', 'max_depth': 3}\n",
      "0.251 (+/-0.266) for {'criterion': 'gini', 'max_depth': 4}\n",
      "0.339 (+/-0.312) for {'criterion': 'gini', 'max_depth': 5}\n",
      "0.308 (+/-0.189) for {'criterion': 'gini', 'max_depth': 6}\n",
      "0.308 (+/-0.114) for {'criterion': 'gini', 'max_depth': 7}\n",
      "0.040 (+/-0.098) for {'criterion': 'entropy', 'max_depth': 2}\n",
      "0.258 (+/-0.290) for {'criterion': 'entropy', 'max_depth': 3}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.308 (+/-0.232) for {'criterion': 'entropy', 'max_depth': 4}\n",
      "0.345 (+/-0.322) for {'criterion': 'entropy', 'max_depth': 5}\n",
      "0.386 (+/-0.182) for {'criterion': 'entropy', 'max_depth': 6}\n",
      "0.336 (+/-0.128) for {'criterion': 'entropy', 'max_depth': 7}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.89      0.85       285\n",
      "          1       0.52      0.39      0.45        89\n",
      "\n",
      "avg / total       0.75      0.77      0.76       374\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 3}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.757 (+/-0.018) for {'criterion': 'gini', 'max_depth': 2}\n",
      "0.765 (+/-0.030) for {'criterion': 'gini', 'max_depth': 3}\n",
      "0.749 (+/-0.050) for {'criterion': 'gini', 'max_depth': 4}\n",
      "0.754 (+/-0.110) for {'criterion': 'gini', 'max_depth': 5}\n",
      "0.741 (+/-0.097) for {'criterion': 'gini', 'max_depth': 6}\n",
      "0.719 (+/-0.043) for {'criterion': 'gini', 'max_depth': 7}\n",
      "0.757 (+/-0.018) for {'criterion': 'entropy', 'max_depth': 2}\n",
      "0.757 (+/-0.027) for {'criterion': 'entropy', 'max_depth': 3}\n",
      "0.759 (+/-0.033) for {'criterion': 'entropy', 'max_depth': 4}\n",
      "0.746 (+/-0.079) for {'criterion': 'entropy', 'max_depth': 5}\n",
      "0.757 (+/-0.104) for {'criterion': 'entropy', 'max_depth': 6}\n",
      "0.733 (+/-0.051) for {'criterion': 'entropy', 'max_depth': 7}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.89      0.86       285\n",
      "          1       0.55      0.44      0.49        89\n",
      "\n",
      "avg / total       0.77      0.78      0.77       374\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 4}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.671 (+/-0.097) for {'criterion': 'gini', 'max_depth': 2}\n",
      "0.670 (+/-0.079) for {'criterion': 'gini', 'max_depth': 3}\n",
      "0.686 (+/-0.055) for {'criterion': 'gini', 'max_depth': 4}\n",
      "0.658 (+/-0.142) for {'criterion': 'gini', 'max_depth': 5}\n",
      "0.618 (+/-0.142) for {'criterion': 'gini', 'max_depth': 6}\n",
      "0.609 (+/-0.103) for {'criterion': 'gini', 'max_depth': 7}\n",
      "0.661 (+/-0.093) for {'criterion': 'entropy', 'max_depth': 2}\n",
      "0.651 (+/-0.112) for {'criterion': 'entropy', 'max_depth': 3}\n",
      "0.657 (+/-0.069) for {'criterion': 'entropy', 'max_depth': 4}\n",
      "0.630 (+/-0.112) for {'criterion': 'entropy', 'max_depth': 5}\n",
      "0.589 (+/-0.104) for {'criterion': 'entropy', 'max_depth': 6}\n",
      "0.607 (+/-0.122) for {'criterion': 'entropy', 'max_depth': 7}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.87      0.86       285\n",
      "          1       0.55      0.52      0.53        89\n",
      "\n",
      "avg / total       0.78      0.78      0.78       374\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'max_depth': [2,3,4,5,6,7],'criterion': ['gini']},\n",
    "                    {'max_depth': [2,3,4,5,6,7],'criterion': ['entropy']}]\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(DecisionTreeClassifier(), tuned_parameters, cv=5,\n",
    "                       scoring=score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_curve, classification_report, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "sns.set_color_codes(\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnUAAAH9CAYAAAB8/Ip8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fe0fd198d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test)[:,1], pos_label=1)\n",
    "lw=2\n",
    "plt.plot(fpr, tpr, lw=lw, label='Roc curve')\n",
    "plt.plot([0,1], [0, 1])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Roc curve')\n",
    "plt.savefig(\"Roc.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
